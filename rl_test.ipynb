{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36641eb4",
   "metadata": {},
   "source": [
    "```\n",
    "python -m drivingppo.simsim\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8de637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from drivingppo.train import run\n",
    "import time\n",
    "from typing import Literal, Callable\n",
    "import random\n",
    "from random import randint\n",
    "\n",
    "from drivingppo.world import World, Car, OBSTACLE_VALUE, create_empty_map, angle_of, distance_of, pi, pi2, rad_to_deg\n",
    "from drivingppo.environment import WorldEnv\n",
    "from drivingppo.common import LIDAR_NUM, LIDAR_RANGE, LIDAR_START, LIDAR_END\n",
    "from drivingppo.model import run\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv, DummyVecEnv\n",
    "\n",
    "LOG_DIR = \"./ppo_tensorboard_logs/\"\n",
    "CHECKPOINT_DIR = './ppo_world_checkpoints/'\n",
    "\n",
    "from world_samples import gen_0, gen_11, gen_12, gen_21, gen_22, gen_inv\n",
    "from world_samples import gen_env_naive, gen_env_plain, gen_env_obs\n",
    "from world_samples import generate_random_world_plain, generate_world_square, generate_world_simpleLine\n",
    "from world_samples import generate_random_world_narrow, generate_random_world_obs_between, generate_random_world_obs_matrix\n",
    "\n",
    "\n",
    "import math\n",
    "pi = math.pi\n",
    "pi2 = pi*2\n",
    "\n",
    "\n",
    "MAP_W, MAP_H = 150, 150\n",
    "\n",
    "W_CONFIG = {\n",
    "    'lidar_raynum': LIDAR_NUM,\n",
    "    'lidar_range':  LIDAR_RANGE,\n",
    "    'angle_start':  LIDAR_START,\n",
    "    'angle_end':    LIDAR_END,\n",
    "    'near': 2.5,\n",
    "    'far': 30.0,\n",
    "}\n",
    "\n",
    "def testw():\n",
    "    w = 40\n",
    "    h = 30\n",
    "    z = h/2\n",
    "    return World(\n",
    "        wh=(w, h),\n",
    "        player=Car({\n",
    "            'playerPos': {'x': 5, 'z': z},\n",
    "            'playerBodyX': 90.0,\n",
    "            'playerSpeed': 0.0,\n",
    "        }),\n",
    "        obstacle_map=create_empty_map(w, h),\n",
    "        goal_points = [(39, z)],\n",
    "        config=W_CONFIG|{\n",
    "            'far': 999\n",
    "        }\n",
    "    )\n",
    "\n",
    "def runt(\n",
    "        world_generator:Callable[[], World],\n",
    "        model:PPO|str,\n",
    "        time_spd=2.0,\n",
    "        time_step=111,\n",
    "        step_per_control=3,\n",
    "        auto_close_at_end=True,\n",
    "    ):\n",
    "\n",
    "    env = WorldEnv(\n",
    "        world_generator=world_generator,\n",
    "        time_step=time_step,\n",
    "        step_per_control=1,\n",
    "        render_mode='debug',\n",
    "        auto_close_at_end=auto_close_at_end\n",
    "    )\n",
    "\n",
    "    if type(model) == str:\n",
    "        model = PPO.load(CHECKPOINT_DIR+model, env=env)\n",
    "    assert isinstance(model, PPO)\n",
    "\n",
    "    obs, info = env.reset()\n",
    "    terminated = False\n",
    "    truncated = False\n",
    "    episode_reward = 0.0\n",
    "\n",
    "    while not terminated and not truncated:\n",
    "\n",
    "        # action, _ = model.predict(obs, deterministic=True)  # 에이전트가 행동 선택\n",
    "        action = np.array([-0.5, 0.0])\n",
    "        for _ in range(step_per_control):\n",
    "            obs, reward, terminated, truncated, info = env.step(action)  # 행동 실행\n",
    "            episode_reward += reward\n",
    "            env.render()  # 시각화 호출\n",
    "            time.sleep(time_step / 1000.0 / time_spd)# 시각화 프레임을 위해 딜레이 추가\n",
    "            if terminated or truncated: break\n",
    "\n",
    "    print(f\"에피소드 종료. 총 보상: {episode_reward:.2f}\")\n",
    "\n",
    "    env.close()\n",
    "\n",
    "\n",
    "def world_generator():\n",
    "    # # gen_0\n",
    "    # return generate_random_world_plain(map_h=100 , map_w=100 , num=3, goal_dist_min=2,  goal_dist_max=3,  ang_init='p', ang_lim=pi*0.15, spd_init=0)\n",
    "    # # gen_11\n",
    "    # return generate_random_world_plain(map_h=100, map_w=100, num=10, goal_dist_min=2,  goal_dist_max=5,  ang_init='p',    ang_lim=pi*0.15, spd_init=0)\n",
    "    # # gen_12\n",
    "    # return generate_random_world_plain(map_h=150, map_w=150, num=10, goal_dist_min=2,  goal_dist_max=10, ang_init='half', ang_lim=pi*0.3,  spd_init='rand')\n",
    "    # # gen_21\n",
    "    return generate_random_world_plain(map_h=150, map_w=150, num=18, goal_dist_min=4,  goal_dist_max=15, ang_init='rand', ang_lim=pi*0.3, spd_init=0.0)\n",
    "    # # gen_22\n",
    "    # return generate_random_world_plain(map_h=150, map_w=150, num=7,  goal_dist_min=20, goal_dist_max=25, ang_init='rand', ang_lim=pi*0.8, spd_init='rand')\n",
    "    # # gen_23\n",
    "    # return generate_random_world_plain(map_h=150, map_w=150, num=3, goal_dist_min=20, goal_dist_max=29, ang_init='rand', ang_lim=pi*0.1, spd_init=0, pos_init='corner')\n",
    "\n",
    "    # return generate_random_world_obs_matrix(num=11, obs_dist=randint(10, 18))\n",
    "    # return generate_random_world_narrow(num=9, hollow_radius=randint(4, 10))\n",
    "    # return generate_random_world_obs_between(num=6)\n",
    "    # return generate_world_square(randint(30, 50), randint(30, 50), num=4)\n",
    "\n",
    "# run(world_generator, '0')\n",
    "# run(world_generator, '1_naive')\n",
    "run(world_generator, '2_plain', auto_close_at_end=False)\n",
    "# run(world_generator, '3_withobs')\n",
    "# run(world_generator, '3_withobs_2')\n",
    "# run(world_generator, 'ppo', auto_close_at_end=False)\n",
    "\n",
    "print('#########')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69a0bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 1회 실행 결과 확인\n",
    "from drivingppo.common import LOOKAHEAD_POINTS, LIDAR_NUM\n",
    "from drivingppo.environment import WorldEnv, distance_score_near, distance_score_far\n",
    "\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "env = WorldEnv(\n",
    "    world_generator=None,\n",
    "    render_mode='debug',\n",
    "    auto_close_at_end=False\n",
    ")\n",
    "model = PPO.load('./ppo_world_checkpoints/ppo.zip', env=env)\n",
    "\n",
    "path_data = []\n",
    "for i in range(LOOKAHEAD_POINTS):\n",
    "    distance = 15.2\n",
    "    angle = 0\n",
    "    path_data.extend([distance_score_near(distance), angle, np.cos(angle)])\n",
    "obs_near = [0.0 for _ in range(LIDAR_NUM)]\n",
    "\n",
    "# agent_speed, path_data, obs_near, obs_nearest_angle, obs_nearest_near\n",
    "np.array([0.0] + path_data + obs_near + [0.0, 0.0], dtype=np.float32)\n",
    "\n",
    "# ppo 로그 파일(./logs/ppo.csv)에서 obs 부분만 여기 복붙하여 확인\n",
    "obs = np.array([+8.321,+0.057,+0.091,+0.996,+0.056,+0.082,+0.997,+0.056,+0.073,+0.997,+0.055,+0.064,+0.998,+0.054,+0.055,+0.998,+0.406,+0.714,+0.689,+0.657,+0.616,+0.562,+0.491,+0.394,+0.000,+0.000,+0.000,+0.000,+0.000,+0.000,+0.000,+0.000,+0.000,+0.000,+0.000,+0.000,+0.000,+0.000,+0.000,+0.000,+0.000,+0.000,+0.000,+0.000,+0.000,+0.000,+0.000\n",
    "])\n",
    "\n",
    "action, _ = model.predict(obs, deterministic=True)\n",
    "\n",
    "print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691b476c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WorldController 켜기\n",
    "\n",
    "from drivingppo.world import World, Car, create_empty_map, angle_of, distance_of, rad_to_deg\n",
    "from drivingppo.common import MAP_W, MAP_H, LOOKAHEAD_POINTS, LIDAR_NUM, LIDAR_RANGE, LIDAR_START, LIDAR_END, OBSERVATION_DIM\n",
    "from drivingppo.environment import distance_score_near, distance_score_far, apply_action, observation_str, action_str\n",
    "from drivingppo.simsim import WorldController\n",
    "\n",
    "player = Car({\n",
    "    'playerPos': {'x': 10, 'z': 10},\n",
    "    \"playerSpeed\": 0,\n",
    "    \"playerBodyX\": 270 * rad_to_deg,\n",
    "    \"playerBodyY\": 0,\n",
    "    \"playerBodyZ\": 0,\n",
    "    \"playerHealth\": 0,\n",
    "    \"playerTurretX\": 0,\n",
    "    \"playerTurretY\": 0,\n",
    "})\n",
    "\n",
    "# obstacle_map, w, h = load_obstacle_map('./map-50.txt')\n",
    "\n",
    "goal_points = [(10, 100), (100, 150), (150, 100), (200, 200), (250, 250)]\n",
    "goal_points = []\n",
    "\n",
    "world = World(\n",
    "    player=player,\n",
    "    wh=(MAP_W, MAP_H),\n",
    "#   obstacle_map=obstacle_map,\n",
    "    goal_points=goal_points,\n",
    "    config={\n",
    "        'lidar_range': 20,\n",
    "        'lidar_raynum': 10,\n",
    "        'angle_start': -pi/4,\n",
    "        'angle_end': pi/4,\n",
    "        'use_stop': True\n",
    "})\n",
    "\n",
    "WorldController(\n",
    "    world,\n",
    "    time_accel=1,\n",
    "    use_real_time=False,\n",
    "    frame_delay=33,\n",
    "    config={\n",
    "        'TrackingMode': False,\n",
    "        'LogMode': True,\n",
    "        'api_delay': 1000\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47475277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 거리점수 확인\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from drivingppo.environment import distance_score_near\n",
    "from drivingppo.environment import distance_score_far\n",
    "\n",
    "# def distance_score_near(x:float) -> float:\n",
    "#     d = x + 10.0\n",
    "#     x = 100./d/d\n",
    "#     if x <= 1:\n",
    "#         return x\n",
    "#     else:\n",
    "#         return 1.0\n",
    "\n",
    "# def distance_score_far(distance:float) -> float:\n",
    "#     return math.log(distance + 1.0)/10.0\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "xs = np.array(range(4000))/100\n",
    "nears = np.array([distance_score_near(x) for x in xs])\n",
    "fars  = np.array([distance_score_far(x)  for x in xs])\n",
    "\n",
    "print('NEAR')\n",
    "for x in range(0, 21):\n",
    "    print(f'{x}: {distance_score_near(x):.4f}')\n",
    "\n",
    "print('FAR')\n",
    "for x in range(0, 21):\n",
    "    print(f'{x}: {distance_score_far(x):.4f}')\n",
    "\n",
    "axs[0].plot(xs, nears)\n",
    "axs[0].grid(True)\n",
    "axs[0].set_yticks([0.0, 0.5, 1.0])\n",
    "axs[0].set_xticks([0, 1, 2, 10, 20])\n",
    "\n",
    "axs[1].plot(xs, fars)\n",
    "axs[1].grid(True)\n",
    "# axs[1].set_yticks([0.0, 0.5, 1.0])\n",
    "axs[1].set_xticks([0, 1, 10, 20, 30, 40])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
