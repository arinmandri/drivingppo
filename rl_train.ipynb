{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88734266",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"wwwwwwwwwwwwwwwwwwwwwwwwww\"\n",
    "\n",
    "gdrive_path = f\"/content/drive/Othercomputers/내 노트북/gdrive/dppos/{name}\"\n",
    "\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    !cp    \"{gdrive_path}/world_samples.py\" world_samples.py\n",
    "    !cp -r \"{gdrive_path}/drivingppo\"       drivingppo/\n",
    "    !mkdir -p \"{gdrive_path}/checks\" \"{gdrive_path}/logs\"\n",
    "    !pip uninstall -y gym\n",
    "    !pip install gymnasium stable-baselines3\n",
    "except ModuleNotFoundError:\n",
    "    print('코랩아님')\n",
    "\n",
    "\n",
    "def colabflush():\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        !mv checks/* \"{gdrive_path}/checks/\"\n",
    "        !mv logs/*   \"{gdrive_path}/logs/\"\n",
    "    except ModuleNotFoundError:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b6919b",
   "metadata": {},
   "source": [
    "텐서보드 log 확인\n",
    "\n",
    "```\n",
    "tensorboard --logdir ./logs/\n",
    "```\n",
    "\n",
    "[http://localhost:6006](http://localhost:6006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1f6ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from drivingppo.common import set_seed\n",
    "from drivingppo.environment import WorldEnv, get_path_features\n",
    "from drivingppo.model import create_model, train, linear_schedule, evaluate\n",
    "from drivingppo.model import (\n",
    "    NoFeaturesExtractor,\n",
    "    VMLPFeaturesExtractor,\n",
    "    Shwp1FeaturesExtractor,\n",
    ")\n",
    "from world_samples import gen_1t, gen_2t, gen_3t, gen_3l\n",
    "\n",
    "# from IPython.display import clear_output\n",
    "\n",
    "#########################################################\n",
    "\n",
    "t0 = time.strftime('%y%m%d-%H%M')\n",
    "tb_log = True\n",
    "\n",
    "policy_kwargs=dict(\n",
    "    features_extractor_class=NoFeaturesExtractor,\n",
    "    features_extractor_kwargs=dict(\n",
    "        # conv_out_channels=16,\n",
    "    ),\n",
    "    net_arch=dict(\n",
    "        pi=[512, 512],\n",
    "        vf=[512, 512, 256]\n",
    "    )\n",
    ")\n",
    "\n",
    "#########################################################\n",
    "\n",
    "print('PATH_FEATURE_FUNCTION: ', get_path_features)\n",
    "\n",
    "def a(seed):\n",
    "    run_name = f'{name}-{t0}-{seed}'\n",
    "    print('RUN:', run_name)\n",
    "\n",
    "    count_max = 20\n",
    "\n",
    "    model = create_model(\n",
    "        policy_kwargs=policy_kwargs,\n",
    "    )\n",
    "\n",
    "    print(f'=== 1단계')\n",
    "    count = 0\n",
    "    while True:\n",
    "        count += 1\n",
    "        set_seed(seed)\n",
    "        model = train(\n",
    "            model=model,\n",
    "            # save_path=f'{prefix}-{seed}--1',\n",
    "            gen_env=lambda: WorldEnv(world_generator=gen_1t, time_gain_limit=9_000, time_gain_per_waypoint_rate=0, collision_ending=False),\n",
    "            tb_log=tb_log,\n",
    "            run_name=run_name,\n",
    "            steps=4096,\n",
    "            lr=9e-4,\n",
    "            gamma=0.8,\n",
    "            progress_display=None,\n",
    "            seed=seed\n",
    "        )\n",
    "        metrics = evaluate(model, gen_1t, csv_path='', episode_num=100, verbose=False, print_result=False)\n",
    "        endings = metrics['ending/type']\n",
    "        success_rate = (endings.count('arrived') + endings.count('timeout')) / len(endings)\n",
    "        print(f'=== 1단계 ({count}) 성공률: {success_rate*100:.0f}%')\n",
    "        if success_rate >= 0.5 - 0.0001:\n",
    "            break\n",
    "        elif count > count_max:\n",
    "            break\n",
    "    if count > count_max:\n",
    "        print(f'=== 1단계 통과 못함. 그만.')\n",
    "        return\n",
    "\n",
    "    print(f'=== 2단계')\n",
    "    count = 0\n",
    "    while True:\n",
    "        count += 1\n",
    "        set_seed(seed)\n",
    "        model = train(\n",
    "            model=model,\n",
    "            # save_path=f'{prefix}-{seed}--2',\n",
    "            gen_env=lambda: WorldEnv(world_generator=gen_2t, time_gain_limit=12_000, time_gain_per_waypoint_rate=0, collision_ending=False),\n",
    "            tb_log=tb_log,\n",
    "            run_name=run_name,\n",
    "            steps=4096,\n",
    "            lr=5e-4,\n",
    "            gamma=0.95,\n",
    "            progress_display=None,\n",
    "            seed=seed\n",
    "        )\n",
    "        metrics = evaluate(model, gen_2t, csv_path='', episode_num=100, verbose=False, print_result=False)\n",
    "        endings = metrics['ending/type']\n",
    "        success_rate = (endings.count('arrived') + endings.count('timeout')) / len(endings)\n",
    "        print(f'=== 2단계 ({count}) 성공률: {success_rate*100:.0f}%')\n",
    "        if success_rate >= 0.95 - 0.0001:\n",
    "            break\n",
    "        elif count > count_max:\n",
    "            break\n",
    "    if count > count_max:\n",
    "        print(f'=== 2단계 통과 못함. 그만.')\n",
    "        return\n",
    "\n",
    "    print('=== 3단계')\n",
    "    set_seed(seed)\n",
    "    model = train(\n",
    "        model=model,\n",
    "        gen_env=lambda: WorldEnv(world_generator=gen_3t, time_gain_limit=20_000, time_gain_per_waypoint_rate=0),\n",
    "        tb_log=tb_log,\n",
    "        run_name=run_name,\n",
    "        # save_freq=409_6000//10//4,\n",
    "        steps=409_6000,\n",
    "        lr=linear_schedule(3e-4),\n",
    "        gamma=1,\n",
    "        seed=seed\n",
    "    )\n",
    "    model = train(  # 학습률 스케줄러 안 쓰도록 모델 저장\n",
    "        model=model,\n",
    "        save_path=f'{name}-{seed}',\n",
    "        gen_env=lambda: WorldEnv(world_generator=gen_3t),\n",
    "        steps=0,\n",
    "        lr=0.0,\n",
    "    )\n",
    "    set_seed(seed)\n",
    "    evaluate(model, gen_3l, episode_num=100, csv_path='', verbose=False, print_result=True)\n",
    "\n",
    "    colabflush()\n",
    "\n",
    "    return model\n",
    "\n",
    "colabflush()\n",
    "model = a(100)\n",
    "model = a(200)\n",
    "model = a(300)\n",
    "model = a(400)\n",
    "model = a(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ca11f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 학습률 스케줄 쓰면 코랩에서 돌린 게 내 컴에서 실행이 안 됨. 그거만 덮어쓰고 다시 저장.\n",
    "# from stable_baselines3 import PPO\n",
    "\n",
    "# path = 'checks/wwwwwwwwwwwwwww'\n",
    "\n",
    "# model = PPO.load(\n",
    "#     path=path,\n",
    "#     learning_rate=0.0,\n",
    "# )\n",
    "# model.save(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b41782",
   "metadata": {},
   "source": [
    "| `log_std` | 실제 표준편차 σ | 탐색 수준 | 비고 |\n",
    "| --- | --- | --- | --- |\n",
    "| 0 | 1.0 | 매우 높음 | 행동 공간 전체를 휘젓고 다니는 수준. 초기 학습 시 강한 탐색이 필요할 때 사용. |\n",
    "| -0.5 | ≈ 0.6 | 높음 | 행동의 변동폭이 큼. 기존 정책이 굳었을 때 강제 리셋용으로 권장되는 값. |\n",
    "| -1 | ≈ 0.37 | 보통 | 안정적인 주행과 탐색이 공존하는 수준. |\n",
    "| -2 | ≈ 0.13 | 낮음 | 어느 정도 최적화가 진행된 상태. 정밀한 제어를 시작함. |\n",
    "| \\~-3.0 | \\< 0.05 | 거의 없음 | 수렴 완료 단계. 거의 결정론적(Deterministic)인 행동을 보임. |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
